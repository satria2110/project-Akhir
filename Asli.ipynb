{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "24d6648c-706a-4b34-a79b-ab075bb7f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5926cce-333a-4330-9ca7-286708f06bec",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.4' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/PC/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Daftar folder yang berisi gambar\n",
    "folders = [\"krisko\", \"rama\", \"ryo\", \"satria\", \"yoga\"]\n",
    "\n",
    "# Inisialisasi list untuk menyimpan fitur\n",
    "features_list = []\n",
    "\n",
    "# Loop untuk setiap folder\n",
    "for folder in folders:\n",
    "    print(f\"Processing images in folder: {folder}\")\n",
    "    \n",
    "    # Path ke folder input dan label\n",
    "    folder_path = f\"DataJari/{folder}/\"\n",
    "    label = folders.index(folder)\n",
    "    \n",
    "    # Loop untuk setiap gambar di dalam folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Baca gambar\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            # Konversi ke grayscale\n",
    "            gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Thresholding menggunakan Otsu's thresholding\n",
    "            _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "            \n",
    "            # Morphological closing untuk membersihkan hasil thresholding\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            binary_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "            # Ekstraksi fitur dari gambar sidik jari yang sudah disegmentasi\n",
    "            red_channel = img[:,:,0]\n",
    "            green_channel = img[:,:,1]\n",
    "            blue_channel = img[:,:,2]\n",
    "            \n",
    "            blue_channel[blue_channel == 255] = 0\n",
    "            green_channel[green_channel == 255] = 0\n",
    "            red_channel[red_channel == 255] = 0\n",
    "            \n",
    "            red_mean = np.mean(red_channel)\n",
    "            green_mean = np.mean(green_channel)\n",
    "            blue_mean = np.mean(blue_channel)\n",
    "            \n",
    "            red_std = np.std(red_channel)\n",
    "            green_std = np.std(green_channel)\n",
    "            blue_std = np.std(blue_channel)\n",
    "            \n",
    "            glcm_matrix = graycomatrix(gray_image, [1], [0], levels=256, symmetric=True, normed=True)\n",
    "            \n",
    "            contrast = graycoprops(glcm_matrix, 'contrast')[0, 0]\n",
    "            dissimilarity = graycoprops(glcm_matrix, 'dissimilarity')[0, 0]\n",
    "            \n",
    "            # Menyimpan fitur ke dalam list\n",
    "            features = [red_std, green_std, blue_std, red_mean, green_mean, blue_mean, contrast, dissimilarity, label]\n",
    "            features_list.append(features)\n",
    "\n",
    "# Buat DataFrame dari fitur-fitur yang sudah diekstraksi\n",
    "columns = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'Y']\n",
    "df = pd.DataFrame(features_list, columns=columns)\n",
    "\n",
    "# Simpan ke file CSV\n",
    "output_file = \"Training.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# Cetak DataFrame untuk memverifikasi\n",
    "print(\"DataFrame saved to:\", output_file)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc747ed4-1a7c-4072-b5bd-47fcc99fb458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data training dan testing sudah dibagi dalam CSV.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Membaca file CSV yang berisi fitur dan label\n",
    "df = pd.read_csv(\"Training.csv\")\n",
    "\n",
    "# Memisahkan fitur (X) dan label (Y)\n",
    "X = df.drop('Y', axis=1)  # Memilih semua kolom kecuali kolom 'Y' sebagai fitur\n",
    "y = df['Y']  # Kolom 'Y' sebagai label\n",
    "\n",
    "# Membagi data menjadi training dan testing dengan stratifikasi\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "# Simpan data training ke CSV\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "train_df.to_csv(\"Training_split.csv\", index=False)\n",
    "\n",
    "# Simpan data testing ke CSV\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "test_df.to_csv(\"Testing_split.csv\", index=False)\n",
    "\n",
    "print(\"Data training dan testing sudah dibagi dalam CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b624a349-aad6-4202-90a7-3de6675d670a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle  # Impor pickle untuk menyimpan model\n",
    "\n",
    "# Memuat data dari file CSV (asumsi nama file yang sesuai)\n",
    "X_train = pd.read_csv(\"Training_split.csv\").drop('Y', axis=1)\n",
    "y_train = pd.read_csv(\"Training_split.csv\")['Y']\n",
    "X_test = pd.read_csv(\"Testing_split.csv\").drop('Y', axis=1)\n",
    "y_test = pd.read_csv(\"Testing_split.csv\")['Y']\n",
    "\n",
    "# Skala fitur (opsional, tetapi direkomendasikan)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Buat model LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)  # Iterasi yang ditingkatkan untuk ketahanan\n",
    "\n",
    "try:\n",
    "  # Latih model pada data yang diskalakan\n",
    "  model.fit(X_train_scaled, y_train)\n",
    "\n",
    "except ConvergenceWarning:\n",
    "  print(\"ConvergenceWarning: Model mungkin tidak terkonvergensi dengan sempurna.\")\n",
    "  # Anda mungkin ingin mencoba penyesuaian lebih lanjut di sini (misalnya, solver berbeda)\n",
    "\n",
    "# Evaluasi performa model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "akurasi = accuracy_score(y_test, y_pred)\n",
    "print(f\"Akurasi model: {akurasi}\")\n",
    "\n",
    "# Simpan model yang telah dilatih\n",
    "pickle.dump(model, open(\"model_sidik_jari.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "389456c0-809a-4f33-bee2-998cee5378e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Prediction: [1]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn import svm\n",
    "\n",
    "# Function to train SVM classifier\n",
    "def train_classifier(X_train, y_train):\n",
    "    clf = svm.SVC(kernel=\"rbf\", C=50)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "# Function to save trained model\n",
    "def save_classifier(clf, model_path):\n",
    "    joblib.dump(clf, model_path)\n",
    "\n",
    "# Function to load trained model\n",
    "def load_classifier(model_path):\n",
    "    clf = joblib.load(model_path)\n",
    "    return clf\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Train or load SVM model\n",
    "    train_model = False  # Set to True if you want to train the model\n",
    "    model_path = \"model_sidik_jari.pkl\"\n",
    "\n",
    "    if train_model:\n",
    "        # Example code for training model\n",
    "        X_train = [...]  # Your training data\n",
    "        y_train = [...]  # Your training labels\n",
    "        clf = train_classifier(X_train, y_train)\n",
    "        save_classifier(clf, model_path)\n",
    "        print(\"Model trained and saved.\")\n",
    "\n",
    "    else:\n",
    "        # Load trained model\n",
    "        clf = load_classifier(model_path)\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "    # Example fingerprint image (replace with your input method)\n",
    "    fingerprint_image = cv2.imread(\"DataJari/yoga/yoga3.png\")  # Example image\n",
    "    \n",
    "    # Example feature extraction (replace with your actual feature extraction code)\n",
    "    features = extract_features_from_fingerprint(fingerprint_image)\n",
    "    features = [features]  # Reshape features if needed\n",
    "    \n",
    "    # Example prediction\n",
    "    prediction = clf.predict(features)\n",
    "    print(\"Prediction:\", prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
